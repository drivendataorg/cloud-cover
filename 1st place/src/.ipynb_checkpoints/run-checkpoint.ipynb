{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cloud Coverge Percentage\n",
    "It is assumed that competition training data is available in ../../data directory\n",
    "It will generate csv file name cloud_pct.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compute_cloud_coverage.py --data_dir ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv('./cloud_pct.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training For Best Submission\n",
    "### Training for UNET with backbaone as timm-efficientnet-b1\n",
    "**The code will generate model weights in model directory with name timm-efficientnet-b1-fold<0-4>.pth**\n",
    "\n",
    "For Windows machine num_worker should be set as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python unet_efficient_net_b1_train_fp16_custom_aug.py --data_dir ../../data --fold_num 0 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16_custom_aug.py --data_dir ../../data --fold_num 1 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16_custom_aug.py --data_dir ../../data --fold_num 2 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16_custom_aug.py --data_dir ../../data --fold_num 3 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16_custom_aug.py --data_dir ../../data --fold_num 4 --num_worker 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for SegformerForSemanticSegmentation model as available in HuggingFace transformers library with pretrain model 'nvidia/segformer-b1-finetuned-ade-512-512'\n",
    "\n",
    "**The code will generate model weights in model directory with name segformer_b1-fold<0-4>.pth**\n",
    "\n",
    "For Windows machine num_worker should be set as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python segformer_b1_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 0 --num_worker 6\n",
    "!python segformer_b1_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 1 --num_worker 6\n",
    "!python segformer_b1_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 2 --num_worker 6\n",
    "!python segformer_b1_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 3 --num_worker 6\n",
    "!python segformer_b1_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 4 --num_worker 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training For Third Best Submission\n",
    "### Training for UNET with backbaone as timm-efficientnet-b1\n",
    "Execute following commmand to train UNET with backbaone as tf_efficientnetv2_b2 backbone\n",
    "\n",
    "**The code will generate model weights in model directory with name tf_efficientnetv2_b2-fold<0-4>.pth**\n",
    "\n",
    "For Windows machine num_worker should be set as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python unet_efficient_netV2_b2_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 0 --num_worker 6\n",
    "!python unet_efficient_netV2_b2_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 1 --num_worker 6\n",
    "!python unet_efficient_netV2_b2_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 2 --num_worker 6\n",
    "!python unet_efficient_netV2_b2_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 3 --num_worker 6\n",
    "!python unet_efficient_netV2_b2_train_fp16_custom_aug.py --data_dir ../../data/ --fold_num 4 --num_worker 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute following commmand to train UNET with backbaone as timm-efficientnet-b1 backbone\n",
    "**The code will generate model weights in model directory with name timm-efficientnet-b1-fold<0-4>_wo_ca.pth**\n",
    "*This code is not using custom augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python unet_efficient_net_b1_train_fp16.py --data_dir ../../data/ --fold_num 0 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16.py --data_dir ../../data/ --fold_num 1 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16.py --data_dir ../../data/ --fold_num 2 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16.py --data_dir ../../data/ --fold_num 3 --num_worker 6\n",
    "!python unet_efficient_net_b1_train_fp16.py --data_dir ../../data/ --fold_num 4 --num_worker 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Submission Generation\n",
    "*The execution of notebook will create directory with named segformer_b1_unet_effnet_b1_ensemble_submission. The directory has neecessary structure as required for competition.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "subm_folder = 'segformer_b1_unet_effnet_b1_ensemble_submission'\n",
    "submission_path = Path(subm_folder)\n",
    "submission_path.mkdir(exist_ok=True)\n",
    "submission_assets_path = submission_path / \"assets\"\n",
    "submission_assets_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_effnet = submission_assets_path / \"eff1_4ch\"\n",
    "submission_assets_path_effnet.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_segformer = submission_assets_path / \"segformer-b1\"\n",
    "submission_assets_path_segformer.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "for f in glob.glob(r'../models/timm-efficientnet-b1-fold[0-4].pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnet/f1)\n",
    "    \n",
    "    \n",
    "for f in glob.glob(r'../models/segformer_b1-fold[0,2,4].pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_segformer/f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file $subm_folder/segformer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp \n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "class SegFormer_b1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegFormer_b1, self).__init__()\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b1-finetuned-ade-512-512')\n",
    "        self.segformer.decode_head.classifier = nn.Conv2d(256,1,kernel_size=1)\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        image = image[:,0:3]\n",
    "        \n",
    "        batch_size = len(image)\n",
    "        with amp.autocast():\n",
    "            mask = self.segformer(image).logits\n",
    "            mask = F.interpolate(mask, image.shape[-2:], mode=\"bilinear\", align_corners=True)\n",
    "            \n",
    "        return mask\n",
    "    \n",
    "\n",
    "class AmpNet(SegFormer_b1):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AmpNet, self).__init__()\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self,*args):\n",
    "        return super(AmpNet, self).forward(*args)\n",
    "\n",
    "  #True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file $subm_folder/cloud_model.py\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.efficientnet import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# These transformations will be passed to our model class\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, chip_ids_df, \n",
    "                 x_path = '../data/train_features/', \n",
    "                 y_path= '../data/train_labels/', \n",
    "                 bands=[4,3,2],transforms=None):\n",
    "        self.data = chip_ids_df\n",
    "        self.data_path = x_path\n",
    "        self.label_path = y_path\n",
    "        self.bands = bands\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx]\n",
    "        chip_id = img.chip_id\n",
    "        imgs = []\n",
    "        for b in self.bands:\n",
    "            pth = f'{self.data_path}/{chip_id}/B0{b}.tif'\n",
    "            with rasterio.open(pth) as img_file:\n",
    "                img = img_file.read(1).astype(float)\n",
    "                img = (img/2**16).astype(np.float32)\n",
    "                imgs.append(img)\n",
    "        x_arr= np.stack(imgs,axis=-1)\n",
    "        \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1])\n",
    "        sample = {\"chip_id\": chip_id, \"chip\": x_arr}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Net4CH(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(Net4CH, self).__init__()\n",
    "\n",
    "        aux_params=dict(\n",
    "                        pooling='avg',             # one of 'avg', 'max'\n",
    "                        dropout=0.3,               # dropout ratio, default is None\n",
    "                        activation=None,      # activation function, default is None\n",
    "                        classes=1,\n",
    "                    ) \n",
    "        self.unet = smp.Unet(\n",
    "                    encoder_name=params['backbone'],        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights=params['weights'],     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                    decoder_attention_type= None,                      # model output channels (number of classes in your dataset)\n",
    "                    classes=1,aux_params=aux_params\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        batch_size = len(image)\n",
    "        mask,logit = self.unet(image)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file $subm_folder/main.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "import typer\n",
    "\n",
    "\n",
    "from segformer import SegFormer_b1,AmpNet\n",
    "from cloud_model import CloudDataset,Net4CH\n",
    "import torchvision\n",
    "\n",
    "ROOT_DIRECTORY = Path(\"/codeexecution\")\n",
    "PREDICTIONS_DIRECTORY = ROOT_DIRECTORY / \"predictions\"\n",
    "ASSETS_DIRECTORY = ROOT_DIRECTORY / \"assets\"\n",
    "DATA_DIRECTORY = ROOT_DIRECTORY / \"data\"\n",
    "INPUT_IMAGES_DIRECTORY = DATA_DIRECTORY / \"test_features\"\n",
    "\n",
    "\n",
    "# Make sure the smp loader can find our torch assets because we don't have internet!\n",
    "os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"torch\")\n",
    "GPU=torch.cuda.is_available()\n",
    "print(\"GPU Available\",GPU)\n",
    "\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in chip_ids:\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "def getModel():\n",
    "    model = AmpNet()\n",
    "    model.cuda()\n",
    "    return model\n",
    "\n",
    "def getModel4ch(hparams):\n",
    "    unet_model = Net4CH(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "def prediction_step(data, models,th=0.5,predictions_dir='./'):\n",
    "    is_mixed_precision = True\n",
    "   \n",
    "    chip_ids = data['chip_id']\n",
    "    images = data['chip'].float()\n",
    "    images = images.cuda()\n",
    "\n",
    "    preds = np.zeros((images.shape[0],images.shape[2],images.shape[3]))\n",
    "    \n",
    "    images = torch.stack([images, torchvision.transforms.functional.hflip(images),\n",
    "                            torchvision.transforms.functional.vflip(images)], 0)\n",
    "    n, bs, c, h, w = images.size()\n",
    "    images = images.view(-1, c, h, w)\n",
    "    \n",
    "    #print('prediction_step',preds.shape,images.shape)\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            mask = model(images)\n",
    "            \n",
    "            probs1, probs2, probs3 = torch.split(mask, bs)\n",
    "            probs2 = torchvision.transforms.functional.hflip(probs2)\n",
    "            probs3 = torchvision.transforms.functional.vflip(probs3)\n",
    "            \n",
    "            mask =  (1/3)*probs1 + (1/3)*probs2 + (1/3)*probs3\n",
    "            mask = mask.sigmoid()\n",
    "            preds += mask[:,0].cpu().numpy()\n",
    "    preds /= len(models)\n",
    "    preds = ((preds>0.5)*1).astype(np.uint8)\n",
    "    \n",
    "    for ix in range(len(chip_ids)):\n",
    "        chip_id = chip_ids[ix]\n",
    "        output_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "        #if ix == 0:\n",
    "        #    print('prediction_step',chip_id,preds[ix].shape,(preds[ix]==1).sum())\n",
    "        imwrite(output_path, preds[ix], dtype=np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    "hparams = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weights\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "is_mixed_precision = True\n",
    "import gc\n",
    "def main(\n",
    "    assets_dir_path: Path = ASSETS_DIRECTORY,\n",
    "    test_features_dir: Path = DATA_DIRECTORY / \"test_features\",\n",
    "    predictions_dir: Path = PREDICTIONS_DIRECTORY,\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\"],):\n",
    "\n",
    "    if not test_features_dir.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for test feature images must exist and {test_features_dir} does not exist\"\n",
    "        )\n",
    "    predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    logger.info(\"Loading model\")\n",
    "    # Explicitly set where we expect smp to load the saved resnet from just to be sure\n",
    "    torch.hub.set_dir(assets_dir_path / \"torch/hub\")\n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    assets_dir_path1 = assets_dir_path/'segformer-b1'\n",
    "    model_paths = assets_dir_path1.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getModel()\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    assets_dir_path2 = assets_dir_path/'eff1_4ch'\n",
    "    model_paths = assets_dir_path2.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getModel4ch(hparams)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(\"Finding chip IDs\")\n",
    "    chip_id_metadata = get_metadata(test_features_dir, bands)\n",
    "    \n",
    "    logger.info(f\"Found {len(chip_id_metadata)} test chip_ids. Generating predictions.\")\n",
    "    \n",
    "    #create dataset and data loader\n",
    "    testDataSet = val_dataset = CloudDataset(chip_id_metadata, \n",
    "                                             x_path= test_features_dir, \n",
    "                                             bands = [4,3,2,8])\n",
    "    testDataLoader = torch.utils.data.DataLoader(\n",
    "                        testDataSet,\n",
    "                        batch_size=16,num_workers=4,shuffle=False,pin_memory=False\n",
    "                        )\n",
    "    \n",
    "    for i,data in tqdm(enumerate(testDataLoader),total=len(testDataLoader)):\n",
    "        prediction_step(data,models,predictions_dir=predictions_dir)\n",
    "\n",
    "    logger.success(f\"Inference complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Best Submission Generation\n",
    "*The execution of notebook will create directory with named effnetv2b2_unet_eff1_ensemble. The directory has neecessary structure as required for competition.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "submission_path = Path(\"effnetv2b2_unet_eff1_ensemble\")\n",
    "submission_path.mkdir(exist_ok=True)\n",
    "submission_assets_path = submission_path / \"assets\"\n",
    "submission_assets_path.mkdir(exist_ok=True)\n",
    "submission_assets_path_effnet = submission_assets_path / \"unet-eff1\"\n",
    "submission_assets_path_effnet.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_effnetv2 = submission_assets_path / \"effnetv2b2\"\n",
    "submission_assets_path_effnetv2.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "for f in glob.glob(r'../models/timm-efficientnet-b1-*_wo_ca.pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnet/f1)\n",
    "    \n",
    "    \n",
    "for f in glob.glob(r'../models/tf_efficientnetv2_b2-*.pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnetv2/f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file $submission_path/cloud_model.py\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.efficientnet import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# These transformations will be passed to our model class\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, chip_ids_df, \n",
    "                 x_path = '../data/train_features/', \n",
    "                 y_path= '../data/train_labels/', \n",
    "                 bands=[4,3,2],transforms=None):\n",
    "        self.data = chip_ids_df\n",
    "        self.data_path = x_path\n",
    "        self.label_path = y_path\n",
    "        self.bands = bands\n",
    "        self.transforms = transforms\n",
    "        self.max_values = {4:23104,3:26096,2:27600,8:19568}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx]\n",
    "        chip_id = img.chip_id\n",
    "        imgs = []\n",
    "        for b in self.bands:\n",
    "            pth = f'{self.data_path}/{chip_id}/B0{b}.tif'\n",
    "            with rasterio.open(pth) as img_file:\n",
    "                img = img_file.read(1).astype(float)\n",
    "                img = (img/2**16).astype(np.float32)\n",
    "                imgs.append(img)\n",
    "        x_arr= np.stack(imgs,axis=-1)\n",
    "        \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1])\n",
    "        sample = {\"chip_id\": chip_id, \"chip\": x_arr}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "\n",
    "from segmentation_models_pytorch.unet.decoder import UnetDecoder\n",
    "from segmentation_models_pytorch.base import SegmentationHead\n",
    "\n",
    "class UnetEffNetV2(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(UnetEffNetV2, self).__init__()\n",
    "        norm_cfg = dict(type='BN', requires_grad=True)\n",
    "        self.backbone = timm.create_model('tf_efficientnetv2_b2', features_only=True, \n",
    "                                          out_indices=[0,1,2,3],pretrained=True)\n",
    "        self.decode_head = UnetDecoder(\n",
    "                            encoder_channels=[16, 32, 56, 120],\n",
    "                            decoder_channels=[16, 32, 56, 120],\n",
    "                            n_blocks=4,\n",
    "                            use_batchnorm=True,\n",
    "                            center=False,\n",
    "                            attention_type=None\n",
    "                        )\n",
    "        \n",
    "        self.segment_classifier = SegmentationHead(56,1,upsampling=4)\n",
    "\n",
    "        \n",
    "    def forward(self,image):\n",
    "        image = image[:,0:3]\n",
    "        x = self.backbone(image)\n",
    "        x=self.decode_head(*x)\n",
    "        x=self.segment_classifier(x)\n",
    "        x = F.interpolate(x, image.shape[-2:], mode=\"bilinear\", align_corners=True)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNetEFF1_4CH(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(UNetEFF1_4CH, self).__init__()\n",
    "\n",
    "        aux_params=dict(\n",
    "                        pooling='avg',             # one of 'avg', 'max'\n",
    "                        dropout=0.3,               # dropout ratio, default is None\n",
    "                        activation=None,      # activation function, default is None\n",
    "                        classes=1,\n",
    "                    ) \n",
    "        self.unet = smp.Unet(\n",
    "                    encoder_name=params['backbone'],        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights=params['weights'],     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                    decoder_attention_type= None,                      # model output channels (number of classes in your dataset)\n",
    "                    classes=1,aux_params=aux_params\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        batch_size = len(image)\n",
    "        mask,logit = self.unet(image)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file $submission_path/main.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import typer\n",
    "import gc\n",
    "\n",
    "from cloud_model import UNetEFF1_4CH,CloudDataset,UnetEffNetV2\n",
    "import torchvision\n",
    "\n",
    "ROOT_DIRECTORY = Path(\"/codeexecution\")\n",
    "PREDICTIONS_DIRECTORY = ROOT_DIRECTORY / \"predictions\"\n",
    "ASSETS_DIRECTORY = ROOT_DIRECTORY / \"assets\"\n",
    "DATA_DIRECTORY = ROOT_DIRECTORY / \"data\"\n",
    "INPUT_IMAGES_DIRECTORY = DATA_DIRECTORY / \"test_features\"\n",
    "\n",
    "\n",
    "# Make sure the smp loader can find our torch assets because we don't have internet!\n",
    "os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"torch\")\n",
    "GPU=torch.cuda.is_available()\n",
    "\n",
    "hparams = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weights\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in chip_ids:\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "def getEffv2Model(hparams):\n",
    "    unet_model = UnetEffNetV2(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "def getEffb1Model4ch(hparams):\n",
    "    unet_model = UNetEFF1_4CH(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "def prediction_step(data, models,th=0.5,predictions_dir='./'):\n",
    "   \n",
    "    chip_ids = data['chip_id']\n",
    "    images = data['chip'].float()\n",
    "    if GPU:\n",
    "        images = images.cuda()\n",
    "\n",
    "    preds = np.zeros((images.shape[0],images.shape[2],images.shape[3]))\n",
    "    \n",
    "    images = torch.stack([images, torchvision.transforms.functional.hflip(images),\n",
    "                            torchvision.transforms.functional.vflip(images),\n",
    "                            ], 0)\n",
    "    n, bs, c, h, w = images.size()\n",
    "    images = images.view(-1, c, h, w)\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            mask = model(images)\n",
    "            ##TTA\n",
    "            \n",
    "            probs1, probs2, probs3 = torch.split(mask, bs)\n",
    "\n",
    "            \n",
    "            probs2 = torchvision.transforms.functional.hflip(probs2)\n",
    "            probs3 = torchvision.transforms.functional.vflip(probs3)\n",
    "            \n",
    "            \n",
    "            mask =  (1/3)*probs1 + (1/3)*probs2 + (1/3)*probs3\n",
    "            mask = mask.sigmoid()\n",
    "            preds += mask[:,0].cpu().numpy()\n",
    "    preds /= len(models)\n",
    "    preds = ((preds>0.5)*1).astype(np.uint8)\n",
    "    \n",
    "    for ix in range(len(chip_ids)):\n",
    "        chip_id = chip_ids[ix]\n",
    "        output_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "        imwrite(output_path, preds[ix], dtype=np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    "params = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weight\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "def main(\n",
    "    assets_dir_path: Path = ASSETS_DIRECTORY,\n",
    "    test_features_dir: Path = DATA_DIRECTORY / \"test_features\",\n",
    "    predictions_dir: Path = PREDICTIONS_DIRECTORY,\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\", \"B08\"],):\n",
    "\n",
    "    if not test_features_dir.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for test feature images must exist and {test_features_dir} does not exist\"\n",
    "        )\n",
    "    predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    logger.info(\"Loading model\")\n",
    "    # Explicitly set where we expect smp to load the saved resnet from just to be sure\n",
    "    torch.hub.set_dir(assets_dir_path / \"torch/hub\")\n",
    "    \n",
    "    model_paths = assets_dir_path.glob('*.pth')\n",
    "    models = []\n",
    "    \n",
    "    assets_dir_path1 = assets_dir_path/'effnetv2b2'\n",
    "    model_paths = assets_dir_path1.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getEffv2Model(params)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    assets_dir_path2 = assets_dir_path/'unet-eff1'\n",
    "    model_paths = assets_dir_path2.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getEffb1Model4ch(hparams)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(\"Finding chip IDs\")\n",
    "    chip_id_metadata = get_metadata(test_features_dir, bands)\n",
    "    \n",
    "    logger.info(f\"Found {len(chip_id_metadata)} test chip_ids. Generating predictions.\")\n",
    "    \n",
    "    #create dataset and data loader\n",
    "    testDataSet = val_dataset = CloudDataset(chip_id_metadata, \n",
    "                                             x_path= test_features_dir, \n",
    "                                             bands = [4,3,2,8])\n",
    "    testDataLoader = torch.utils.data.DataLoader(\n",
    "                        testDataSet,\n",
    "                        batch_size=16,num_workers=4,shuffle=False,pin_memory=False\n",
    "                        )\n",
    "    \n",
    "    for i,data in tqdm(enumerate(testDataLoader),total=len(testDataLoader)):\n",
    "        prediction_step(data,models,predictions_dir=predictions_dir)\n",
    "\n",
    "    logger.success(f\"Inference complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
