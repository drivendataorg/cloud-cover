{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:53:23.626528Z",
     "iopub.status.busy": "2021-08-29T09:53:23.626201Z",
     "iopub.status.idle": "2021-08-29T09:53:26.270662Z",
     "shell.execute_reply": "2021-08-29T09:53:26.269796Z",
     "shell.execute_reply.started": "2021-08-29T09:53:23.626495Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "subm_folder = 'segformer_b1_unet_effnet_b1_ensemble_submission'\n",
    "submission_path = Path(subm_folder)\n",
    "submission_path.mkdir(exist_ok=True)\n",
    "submission_assets_path = submission_path / \"assets\"\n",
    "submission_assets_path.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_effnet = submission_assets_path / \"eff1_4ch\"\n",
    "submission_assets_path_effnet.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_segformer = submission_assets_path / \"segformer-b1\"\n",
    "submission_assets_path_segformer.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models\\timm-efficientnet-b1-fold0.pth\n",
      "../models\\timm-efficientnet-b1-fold4.pth\n",
      "../models\\segformer_b1-fold0.pth\n",
      "../models\\segformer_b1-fold2.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import glob\n",
    "for f in glob.glob(r'../models/timm-efficientnet-b1-fold[0-4].pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnet/f1)\n",
    "    \n",
    "    \n",
    "for f in glob.glob(r'../models/segformer_b1-fold[0,2,4].pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_segformer/f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing segformer_b1_unet_effnet_b1_ensemble_submission/segformer.py\n"
     ]
    }
   ],
   "source": [
    "%%file $subm_folder/segformer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp \n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "class SegFormer_b1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegFormer_b1, self).__init__()\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b1-finetuned-ade-512-512')\n",
    "        self.segformer.decode_head.classifier = nn.Conv2d(256,1,kernel_size=1)\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        image = image[:,0:3]\n",
    "        \n",
    "        batch_size = len(image)\n",
    "        with amp.autocast():\n",
    "            mask = self.segformer(image).logits\n",
    "            mask = F.interpolate(mask, image.shape[-2:], mode=\"bilinear\", align_corners=True)\n",
    "            \n",
    "        return mask\n",
    "    \n",
    "\n",
    "class AmpNet(SegFormer_b1):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AmpNet, self).__init__()\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self,*args):\n",
    "        return super(AmpNet, self).forward(*args)\n",
    "\n",
    "  #True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:56.261558Z",
     "iopub.status.busy": "2021-08-29T09:55:56.261233Z",
     "iopub.status.idle": "2021-08-29T09:55:56.279499Z",
     "shell.execute_reply": "2021-08-29T09:55:56.278498Z",
     "shell.execute_reply.started": "2021-08-29T09:55:56.261524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing segformer_b1_unet_effnet_b1_ensemble_submission/cloud_model.py\n"
     ]
    }
   ],
   "source": [
    "%%file $subm_folder/cloud_model.py\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.efficientnet import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# These transformations will be passed to our model class\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, chip_ids_df, \n",
    "                 x_path = '../data/train_features/', \n",
    "                 y_path= '../data/train_labels/', \n",
    "                 bands=[4,3,2],transforms=None):\n",
    "        self.data = chip_ids_df\n",
    "        self.data_path = x_path\n",
    "        self.label_path = y_path\n",
    "        self.bands = bands\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx]\n",
    "        chip_id = img.chip_id\n",
    "        imgs = []\n",
    "        for b in self.bands:\n",
    "            pth = f'{self.data_path}/{chip_id}/B0{b}.tif'\n",
    "            with rasterio.open(pth) as img_file:\n",
    "                img = img_file.read(1).astype(float)\n",
    "                img = (img/2**16).astype(np.float32)\n",
    "                imgs.append(img)\n",
    "        x_arr= np.stack(imgs,axis=-1)\n",
    "        \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1])\n",
    "        sample = {\"chip_id\": chip_id, \"chip\": x_arr}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Net4CH(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(Net4CH, self).__init__()\n",
    "\n",
    "        aux_params=dict(\n",
    "                        pooling='avg',             # one of 'avg', 'max'\n",
    "                        dropout=0.3,               # dropout ratio, default is None\n",
    "                        activation=None,      # activation function, default is None\n",
    "                        classes=1,\n",
    "                    ) \n",
    "        self.unet = smp.Unet(\n",
    "                    encoder_name=params['backbone'],        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights=params['weights'],     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                    decoder_attention_type= None,                      # model output channels (number of classes in your dataset)\n",
    "                    classes=1,aux_params=aux_params\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        batch_size = len(image)\n",
    "        mask,logit = self.unet(image)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:54:15.965815Z",
     "iopub.status.busy": "2021-08-29T09:54:15.965462Z",
     "iopub.status.idle": "2021-08-29T09:54:15.971553Z",
     "shell.execute_reply": "2021-08-29T09:54:15.970367Z",
     "shell.execute_reply.started": "2021-08-29T09:54:15.965780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing segformer_b1_unet_effnet_b1_ensemble_submission/main.py\n"
     ]
    }
   ],
   "source": [
    "%%file $subm_folder/main.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "import typer\n",
    "\n",
    "\n",
    "from segformer import SegFormer_b1,AmpNet\n",
    "from cloud_model import CloudDataset,Net4CH\n",
    "import torchvision\n",
    "\n",
    "ROOT_DIRECTORY = Path(\"/codeexecution\")\n",
    "PREDICTIONS_DIRECTORY = ROOT_DIRECTORY / \"predictions\"\n",
    "ASSETS_DIRECTORY = ROOT_DIRECTORY / \"assets\"\n",
    "DATA_DIRECTORY = ROOT_DIRECTORY / \"data\"\n",
    "INPUT_IMAGES_DIRECTORY = DATA_DIRECTORY / \"test_features\"\n",
    "\n",
    "\n",
    "# Make sure the smp loader can find our torch assets because we don't have internet!\n",
    "os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"torch\")\n",
    "GPU=torch.cuda.is_available()\n",
    "print(\"GPU Available\",GPU)\n",
    "\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in chip_ids:\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "def getModel():\n",
    "    model = AmpNet()\n",
    "    model.cuda()\n",
    "    return model\n",
    "\n",
    "def getModel4ch(hparams):\n",
    "    unet_model = Net4CH(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "def prediction_step(data, models,th=0.5,predictions_dir='./'):\n",
    "    is_mixed_precision = True\n",
    "   \n",
    "    chip_ids = data['chip_id']\n",
    "    images = data['chip'].float()\n",
    "    images = images.cuda()\n",
    "\n",
    "    preds = np.zeros((images.shape[0],images.shape[2],images.shape[3]))\n",
    "    \n",
    "    images = torch.stack([images, torchvision.transforms.functional.hflip(images),\n",
    "                            torchvision.transforms.functional.vflip(images)], 0)\n",
    "    n, bs, c, h, w = images.size()\n",
    "    images = images.view(-1, c, h, w)\n",
    "    \n",
    "    #print('prediction_step',preds.shape,images.shape)\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            mask = model(images)\n",
    "            \n",
    "            probs1, probs2, probs3 = torch.split(mask, bs)\n",
    "            probs2 = torchvision.transforms.functional.hflip(probs2)\n",
    "            probs3 = torchvision.transforms.functional.vflip(probs3)\n",
    "            \n",
    "            mask =  (1/3)*probs1 + (1/3)*probs2 + (1/3)*probs3\n",
    "            mask = mask.sigmoid()\n",
    "            preds += mask[:,0].cpu().numpy()\n",
    "    preds /= len(models)\n",
    "    preds = ((preds>0.5)*1).astype(np.uint8)\n",
    "    \n",
    "    for ix in range(len(chip_ids)):\n",
    "        chip_id = chip_ids[ix]\n",
    "        output_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "        #if ix == 0:\n",
    "        #    print('prediction_step',chip_id,preds[ix].shape,(preds[ix]==1).sum())\n",
    "        imwrite(output_path, preds[ix], dtype=np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    "hparams = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weights\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "is_mixed_precision = True\n",
    "import gc\n",
    "def main(\n",
    "    assets_dir_path: Path = ASSETS_DIRECTORY,\n",
    "    test_features_dir: Path = DATA_DIRECTORY / \"test_features\",\n",
    "    predictions_dir: Path = PREDICTIONS_DIRECTORY,\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\"],):\n",
    "\n",
    "    if not test_features_dir.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for test feature images must exist and {test_features_dir} does not exist\"\n",
    "        )\n",
    "    predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    logger.info(\"Loading model\")\n",
    "    # Explicitly set where we expect smp to load the saved resnet from just to be sure\n",
    "    torch.hub.set_dir(assets_dir_path / \"torch/hub\")\n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    assets_dir_path1 = assets_dir_path/'segformer-b1'\n",
    "    model_paths = assets_dir_path1.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getModel()\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    assets_dir_path2 = assets_dir_path/'eff1_4ch'\n",
    "    model_paths = assets_dir_path2.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getModel4ch(hparams)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(\"Finding chip IDs\")\n",
    "    chip_id_metadata = get_metadata(test_features_dir, bands)\n",
    "    \n",
    "    logger.info(f\"Found {len(chip_id_metadata)} test chip_ids. Generating predictions.\")\n",
    "    \n",
    "    #create dataset and data loader\n",
    "    testDataSet = val_dataset = CloudDataset(chip_id_metadata, \n",
    "                                             x_path= test_features_dir, \n",
    "                                             bands = [4,3,2,8])\n",
    "    testDataLoader = torch.utils.data.DataLoader(\n",
    "                        testDataSet,\n",
    "                        batch_size=16,num_workers=4,shuffle=False,pin_memory=False\n",
    "                        )\n",
    "    \n",
    "    for i,data in tqdm(enumerate(testDataLoader),total=len(testDataLoader)):\n",
    "        prediction_step(data,models,predictions_dir=predictions_dir)\n",
    "\n",
    "    logger.success(f\"Inference complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
