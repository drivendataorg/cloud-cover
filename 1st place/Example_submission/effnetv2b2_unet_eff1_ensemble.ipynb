{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:53:23.626528Z",
     "iopub.status.busy": "2021-08-29T09:53:23.626201Z",
     "iopub.status.idle": "2021-08-29T09:53:26.270662Z",
     "shell.execute_reply": "2021-08-29T09:53:26.269796Z",
     "shell.execute_reply.started": "2021-08-29T09:53:23.626495Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "submission_path = Path(\"effnetv2b2_unet_eff1_ensemble\")\n",
    "submission_path.mkdir(exist_ok=True)\n",
    "submission_assets_path = submission_path / \"assets\"\n",
    "submission_assets_path.mkdir(exist_ok=True)\n",
    "submission_assets_path_effnet = submission_assets_path / \"unet-eff1\"\n",
    "submission_assets_path_effnet.mkdir(exist_ok=True)\n",
    "\n",
    "submission_assets_path_effnetv2 = submission_assets_path / \"effnetv2b2\"\n",
    "submission_assets_path_effnetv2.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models\\timm-efficientnet-b1-fold0_wo_ca.pth\n",
      "../models\\tf_efficientnetv2_b2-fold0.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import glob\n",
    "for f in glob.glob(r'../models/timm-efficientnet-b1-*_wo_ca.pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnet/f1)\n",
    "    \n",
    "    \n",
    "for f in glob.glob(r'../models/tf_efficientnetv2_b2-*.pth'):\n",
    "    print(f)\n",
    "    f1 = Path(f).name\n",
    "    shutil.copyfile(f,submission_assets_path_effnetv2/f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:55:56.261558Z",
     "iopub.status.busy": "2021-08-29T09:55:56.261233Z",
     "iopub.status.idle": "2021-08-29T09:55:56.279499Z",
     "shell.execute_reply": "2021-08-29T09:55:56.278498Z",
     "shell.execute_reply.started": "2021-08-29T09:55:56.261524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing effnetv2b2_unet_eff1_ensemble/cloud_model.py\n"
     ]
    }
   ],
   "source": [
    "%%file $submission_path/cloud_model.py\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.efficientnet import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import torchvision\n",
    "\n",
    "# These transformations will be passed to our model class\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, chip_ids_df, \n",
    "                 x_path = '../data/train_features/', \n",
    "                 y_path= '../data/train_labels/', \n",
    "                 bands=[4,3,2],transforms=None):\n",
    "        self.data = chip_ids_df\n",
    "        self.data_path = x_path\n",
    "        self.label_path = y_path\n",
    "        self.bands = bands\n",
    "        self.transforms = transforms\n",
    "        self.max_values = {4:23104,3:26096,2:27600,8:19568}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx]\n",
    "        chip_id = img.chip_id\n",
    "        imgs = []\n",
    "        for b in self.bands:\n",
    "            pth = f'{self.data_path}/{chip_id}/B0{b}.tif'\n",
    "            with rasterio.open(pth) as img_file:\n",
    "                img = img_file.read(1).astype(float)\n",
    "                img = (img/2**16).astype(np.float32)\n",
    "                imgs.append(img)\n",
    "        x_arr= np.stack(imgs,axis=-1)\n",
    "        \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1])\n",
    "        sample = {\"chip_id\": chip_id, \"chip\": x_arr}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "\n",
    "from segmentation_models_pytorch.unet.decoder import UnetDecoder\n",
    "from segmentation_models_pytorch.base import SegmentationHead\n",
    "\n",
    "class UnetEffNetV2(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(UnetEffNetV2, self).__init__()\n",
    "        norm_cfg = dict(type='BN', requires_grad=True)\n",
    "        self.backbone = timm.create_model('tf_efficientnetv2_b2', features_only=True, \n",
    "                                          out_indices=[0,1,2,3],pretrained=True)\n",
    "        self.decode_head = UnetDecoder(\n",
    "                            encoder_channels=[16, 32, 56, 120],\n",
    "                            decoder_channels=[16, 32, 56, 120],\n",
    "                            n_blocks=4,\n",
    "                            use_batchnorm=True,\n",
    "                            center=False,\n",
    "                            attention_type=None\n",
    "                        )\n",
    "        \n",
    "        self.segment_classifier = SegmentationHead(56,1,upsampling=4)\n",
    "\n",
    "        \n",
    "    def forward(self,image):\n",
    "        image = image[:,0:3]\n",
    "        x = self.backbone(image)\n",
    "        x=self.decode_head(*x)\n",
    "        x=self.segment_classifier(x)\n",
    "        x = F.interpolate(x, image.shape[-2:], mode=\"bilinear\", align_corners=True)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNetEFF1_4CH(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(UNetEFF1_4CH, self).__init__()\n",
    "\n",
    "        aux_params=dict(\n",
    "                        pooling='avg',             # one of 'avg', 'max'\n",
    "                        dropout=0.3,               # dropout ratio, default is None\n",
    "                        activation=None,      # activation function, default is None\n",
    "                        classes=1,\n",
    "                    ) \n",
    "        self.unet = smp.Unet(\n",
    "                    encoder_name=params['backbone'],        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights=params['weights'],     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                    in_channels=4,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                    decoder_attention_type= None,                      # model output channels (number of classes in your dataset)\n",
    "                    classes=1,aux_params=aux_params\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image):\n",
    "        batch_size = len(image)\n",
    "        mask,logit = self.unet(image)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T09:54:15.965815Z",
     "iopub.status.busy": "2021-08-29T09:54:15.965462Z",
     "iopub.status.idle": "2021-08-29T09:54:15.971553Z",
     "shell.execute_reply": "2021-08-29T09:54:15.970367Z",
     "shell.execute_reply.started": "2021-08-29T09:54:15.965780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing effnetv2b2_unet_eff1_ensemble/main.py\n"
     ]
    }
   ],
   "source": [
    "%%file $submission_path/main.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import typer\n",
    "import gc\n",
    "\n",
    "from cloud_model import UNetEFF1_4CH,CloudDataset,UnetEffNetV2\n",
    "import torchvision\n",
    "\n",
    "ROOT_DIRECTORY = Path(\"/codeexecution\")\n",
    "PREDICTIONS_DIRECTORY = ROOT_DIRECTORY / \"predictions\"\n",
    "ASSETS_DIRECTORY = ROOT_DIRECTORY / \"assets\"\n",
    "DATA_DIRECTORY = ROOT_DIRECTORY / \"data\"\n",
    "INPUT_IMAGES_DIRECTORY = DATA_DIRECTORY / \"test_features\"\n",
    "\n",
    "\n",
    "# Make sure the smp loader can find our torch assets because we don't have internet!\n",
    "os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"torch\")\n",
    "GPU=torch.cuda.is_available()\n",
    "\n",
    "hparams = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weights\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in chip_ids:\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "def getEffv2Model(hparams):\n",
    "    unet_model = UnetEffNetV2(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "def getEffb1Model4ch(hparams):\n",
    "    unet_model = UNetEFF1_4CH(hparams)\n",
    "    unet_model.cuda()\n",
    "    return unet_model\n",
    "\n",
    "def prediction_step(data, models,th=0.5,predictions_dir='./'):\n",
    "   \n",
    "    chip_ids = data['chip_id']\n",
    "    images = data['chip'].float()\n",
    "    if GPU:\n",
    "        images = images.cuda()\n",
    "\n",
    "    preds = np.zeros((images.shape[0],images.shape[2],images.shape[3]))\n",
    "    \n",
    "    images = torch.stack([images, torchvision.transforms.functional.hflip(images),\n",
    "                            torchvision.transforms.functional.vflip(images),\n",
    "                            ], 0)\n",
    "    n, bs, c, h, w = images.size()\n",
    "    images = images.view(-1, c, h, w)\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            mask = model(images)\n",
    "            ##TTA\n",
    "            \n",
    "            probs1, probs2, probs3 = torch.split(mask, bs)\n",
    "\n",
    "            \n",
    "            probs2 = torchvision.transforms.functional.hflip(probs2)\n",
    "            probs3 = torchvision.transforms.functional.vflip(probs3)\n",
    "            \n",
    "            \n",
    "            mask =  (1/3)*probs1 + (1/3)*probs2 + (1/3)*probs3\n",
    "            mask = mask.sigmoid()\n",
    "            preds += mask[:,0].cpu().numpy()\n",
    "    preds /= len(models)\n",
    "    preds = ((preds>0.5)*1).astype(np.uint8)\n",
    "    \n",
    "    for ix in range(len(chip_ids)):\n",
    "        chip_id = chip_ids[ix]\n",
    "        output_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "        imwrite(output_path, preds[ix], dtype=np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    "params = {\n",
    "    \"backbone\": 'timm-efficientnet-b1',\n",
    "    \"weight\": \"noisy-student\",\n",
    "}\n",
    "\n",
    "def main(\n",
    "    assets_dir_path: Path = ASSETS_DIRECTORY,\n",
    "    test_features_dir: Path = DATA_DIRECTORY / \"test_features\",\n",
    "    predictions_dir: Path = PREDICTIONS_DIRECTORY,\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\", \"B08\"],):\n",
    "\n",
    "    if not test_features_dir.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for test feature images must exist and {test_features_dir} does not exist\"\n",
    "        )\n",
    "    predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    logger.info(\"Loading model\")\n",
    "    # Explicitly set where we expect smp to load the saved resnet from just to be sure\n",
    "    torch.hub.set_dir(assets_dir_path / \"torch/hub\")\n",
    "    \n",
    "    model_paths = assets_dir_path.glob('*.pth')\n",
    "    models = []\n",
    "    \n",
    "    assets_dir_path1 = assets_dir_path/'effnetv2b2'\n",
    "    model_paths = assets_dir_path1.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getEffv2Model(params)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    assets_dir_path2 = assets_dir_path/'unet-eff1'\n",
    "    model_paths = assets_dir_path2.glob('*.pth')\n",
    "    \n",
    "    for mp in model_paths:\n",
    "        print('Loading Model from Path',mp)\n",
    "        f = torch.load(mp, map_location=torch.device('cpu'))\n",
    "        model = getEffb1Model4ch(hparams)\n",
    "        model.load_state_dict(f)\n",
    "        model.cuda()\n",
    "        models.append(model)\n",
    "        del f\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(\"Finding chip IDs\")\n",
    "    chip_id_metadata = get_metadata(test_features_dir, bands)\n",
    "    \n",
    "    logger.info(f\"Found {len(chip_id_metadata)} test chip_ids. Generating predictions.\")\n",
    "    \n",
    "    #create dataset and data loader\n",
    "    testDataSet = val_dataset = CloudDataset(chip_id_metadata, \n",
    "                                             x_path= test_features_dir, \n",
    "                                             bands = [4,3,2,8])\n",
    "    testDataLoader = torch.utils.data.DataLoader(\n",
    "                        testDataSet,\n",
    "                        batch_size=16,num_workers=4,shuffle=False,pin_memory=False\n",
    "                        )\n",
    "    \n",
    "    for i,data in tqdm(enumerate(testDataLoader),total=len(testDataLoader)):\n",
    "        prediction_step(data,models,predictions_dir=predictions_dir)\n",
    "\n",
    "    logger.success(f\"Inference complete.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
